# Information Theory

### Signals and Noise

1. Entropy 
2. Cross Entropy
3. Signal to noise ratio


### Where it is used

pointers

1. information theory
2. transmission of information
   likely event less information
   unlikely event more information
3. expectation of an event to transmit the average amount of information
   non uniform distribution has smaller length code
4. entropy
5.  entropy from physics to statsitical mechanics
6. entropy of discrete random variable
7. entropy of continous random variable
8. relative entropy, mutual information and KL divergence 
   convex and concave functions
9. Kl divergence entropy and cross entropy for machine learning link between Kl divergence and maximum likelihood


### More links to read up