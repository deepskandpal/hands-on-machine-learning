{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install contractions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport nltk\nimport string\nimport fasttext\nimport contractions\nimport matplotlib as plt\nimport pyLDAvis.sklearn\nfrom collections import Counter\nfrom textblob import TextBlob\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nfrom wordcloud import WordCloud, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import WordNetLemmatizer\npd.options.mode.chained_assignment = None\npd.set_option('display.max_colwidth', 100)\n%matplotlib inline\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/fake-news/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pandas_profile(df):\n    print(train_data.describe())\n    print(train_data.info())\n    from pandas_profiling import ProfileReport\n    prof = ProfileReport(df)\n    prof.to_file(output_file='report.html')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pandas_profile(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nreport = './report.html'\nHTML(filename=report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_sequences(text):\n    from tensorflow.keras.preprocessing.text import Tokenizer\n    tok = Tokenizer()\n    tok.fit_on_texts(text)\n    sequence = tok.texts_to_sequences(text)\n    return sequence\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_data(sentence):\n    if isinstance(sentence, str):\n        clean_sentence = re.sub('[^A-Za-z0-9]+', ' ', sentence)\n        return clean_sentence\n    else:\n        raise ValueError(\"error in sentence\", sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dropna(subset = [\"text\"], inplace=True)\ntrain_data['text'].apply(clean_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_sentence(sentence):\n    if isinstance(sentence, str):\n        return sentence.split()\n\ndef join_sentence(sentence):\n    return ' '.join(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['text_split'] = train_data['text'].apply(split_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['text_split']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\ntrain_data['stopwords_removed'] = train_data['text_split'].apply(lambda x: [word for word in x if word not in stop_words])\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = train_data['stopwords_removed']\nallwords = []\nfor wordlist in words:\n    allwords += wordlist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['text_processed'] = train_data['stopwords_removed'].apply(join_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['text_processed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mostcommon = FreqDist(allwords).most_common(100)\nwordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\nfig = plt.figure(figsize=(30,10), facecolor='white')\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 100 Most Common Words', fontsize=100)\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mostcommon_small = FreqDist(allwords).most_common(25)\nx, y = zip(*mostcommon_small)\nplt.figure(figsize=(50,30))\nplt.margins(0.02)\nplt.bar(x, y)\nplt.xlabel('Words', fontsize=50)\nplt.ylabel('Frequency of Words', fontsize=50)\nplt.yticks(fontsize=40)\nplt.xticks(rotation=60, fontsize=40)\nplt.title('Frequency of 25 Most Common Words', fontsize=60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_by = train_data.groupby('label')['text_processed'].apply(lambda x: Counter(' '.join(x).split()).most_common(25))\ngroup_by_0 = group_by.iloc[0]\nwords0 = list(zip(*group_by_0))[0]\nfreq0 = list(zip(*group_by_0))[1]\nplt.figure(figsize=(50,30))\nplt.bar(words0, freq0)\nplt.xlabel('Words', fontsize=50)\nplt.ylabel('Frequency of Words', fontsize=50)\nplt.yticks(fontsize=40)\nplt.xticks(rotation=60, fontsize=40)\nplt.title('Frequency of 25 Most Common Words for not fake ', fontsize=60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_vectorizer = CountVectorizer(max_df=0.9, min_df=25, max_features=500)\ntf = tf_vectorizer.fit_transform(train_data['text_processed'].values.astype('U'))\ntf_feature_names = tf_vectorizer.get_feature_names()\n# doc_term_matrix = pd.DataFrame(tf.toarray(), columns=list(tf_feature_names))\n# doc_term_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_model = LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=500, random_state=0).fit(tf)\nno_top_words = 10\ndef display_topics(model, feature_names, no_top_words):\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"Topic %d:\" % (topic_idx))\n        print(\" \".join([feature_names[i]\n                          for i in topic.argsort()[:-no_top_words - 1:-1]]))\n              \ndisplay_topics(lda_model, tf_feature_names, no_top_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_by = train_data.groupby('label')['text_processed'].apply(lambda x: Counter(' '.join(x).split()).most_common(25))\ngroup_by_0 = group_by.iloc[1]\nwords0 = list(zip(*group_by_0))[0]\nfreq0 = list(zip(*group_by_0))[1]\nplt.figure(figsize=(50,30))\nplt.bar(words0, freq0)\nplt.xlabel('Words', fontsize=50)\nplt.ylabel('Frequency of Words', fontsize=50)\nplt.yticks(fontsize=40)\nplt.xticks(rotation=60, fontsize=40)\nplt.title('Frequency of 25 Most Common Words for fake', fontsize=60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def max_len(expressions):\n    splitted_expressions = []\n    splitted_expressions.extend(w.split(' ') for w in expressions)\n    maxlen = len(max(splitted_expressions, key=len))\n    return maxlen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_X_y(df):\n    df.dropna(subset = [\"text\"], inplace=True)\n    df['text'].apply(clean_data)\n    text = list(df['text'])\n    sequences = create_sequences(text)\n    maxlen = max_len(text)\n    from keras.preprocessing import sequence\n    X = sequence.pad_sequences(sequences, maxlen=maxlen, padding='post',\n                                              truncating='post')\n    y = df['label']\n    y_train = np.asarray(y).astype('float32')\n    return X , y_train\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = prepare_X_y(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train1 = np.expand_dims(X_train, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\ndef build_model():\n    model = models.Sequential() \n    model.add(layers.LSTM(512, input_shape=(24234, 1), return_sequences=True)) \n    model.add(layers.LSTM(128, return_sequences=False))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) \n    history = model.fit(X_train1, y_train, validation_data=(X_test, y_test),epochs=10, batch_size=12, verbose=1)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = build_model()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nhistory_dict = history.history\nloss_values = history_dict['loss'] \nacc = history_dict['acc'] \nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, loss_values, 'bo', label='Training loss') \nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss') \nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.clf() \nacc_values = history_dict['acc'] \nval_acc_values = history_dict['val_acc']\nplt.plot(epochs, acc, 'bo', label='Training acc') \nplt.plot(epochs, val_acc_values, 'b', label='Validation acc') \nplt.title('Training and validation accuracy') \nplt.xlabel('Epochs')\nplt.ylabel('Loss') \nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}