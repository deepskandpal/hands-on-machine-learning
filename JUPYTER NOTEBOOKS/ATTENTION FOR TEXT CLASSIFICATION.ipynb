{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#   TEXT CLASSIFICATION USING ATTENTION MECHANISIM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  POC using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing attention mechanisim for  sentence-level sentiment analysis dataset collected from the University of California Irvine Machine Learning Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "DIR_PATH = os.path.dirname(os.path.realpath('__file__'))\n",
    "DATASETS = \"datasets\"\n",
    "SENTIMENT_ANALYSIS = \"sentiment labelled sentences\"\n",
    "file_path = os.path.join(DIR_PATH,SENTIMENT_ANALYSIS,\"merged_dataset.txt\")\n",
    "df_sentiment = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
    "df_sentiment.columns = [\"review\", \"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0                           Wow... Loved this place.       1\n",
       "1                                 Crust is not good.       0\n",
       "2          Not tasty and the texture was just nasty.       0\n",
       "3  Stopped by during the late May bank holiday of...       1\n",
       "4  The selection on the menu was great and so wer...       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "review    2000 non-null object\n",
      "rating    2000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sentiment.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation using keras preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Tokenizer()\n",
    "t.fit_on_texts(df_sentiment[\"review\"])\n",
    "text_matrix=t.texts_to_sequences(df_sentiment[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_mat=[]\n",
    "for i in range(len(text_matrix)):\n",
    "    len_mat.append(len(text_matrix[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepanshu.kandpal/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "text_pad = pad_sequences(text_matrix, maxlen=32, padding='post')\n",
    "integer_encode = label_encoder.fit_transform(df_sentiment[\"rating\"])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encode.reshape(len(integer_encode), 1)\n",
    "Y = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(Y.shape)\n",
    "text_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation using Functional API of Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1= Input(shape=(32,))\n",
    "x1=Embedding(input_dim=len(t.word_index.items())+1,output_dim=32,input_length=32,embeddings_regularizer=keras.regularizers.l2(.001))(inputs1)\n",
    "x1=LSTM(100,dropout=0.3,recurrent_dropout=0.2)(x1)\n",
    "outputs1=Dense(2,activation='sigmoid')(x1)\n",
    "model1=Model(inputs1,outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 32, 32)            66304     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 119,706\n",
      "Trainable params: 119,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x13ce94510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x13ce94510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.7294 - acc: 0.4841 - val_loss: 0.7154 - val_acc: 0.4125\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 1s 552us/sample - loss: 0.7028 - acc: 0.5219 - val_loss: 0.7073 - val_acc: 0.4125\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 1s 544us/sample - loss: 0.6946 - acc: 0.5219 - val_loss: 0.7042 - val_acc: 0.4125\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 1s 582us/sample - loss: 0.6920 - acc: 0.5219 - val_loss: 0.7052 - val_acc: 0.4137\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 1s 605us/sample - loss: 0.6899 - acc: 0.5453 - val_loss: 0.6783 - val_acc: 0.6000\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 1s 585us/sample - loss: 0.5790 - acc: 0.7144 - val_loss: 0.4255 - val_acc: 0.8375\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 1s 550us/sample - loss: 0.3670 - acc: 0.8722 - val_loss: 0.2777 - val_acc: 0.9075\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 1s 581us/sample - loss: 0.2262 - acc: 0.9388 - val_loss: 0.2032 - val_acc: 0.9500\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 1s 576us/sample - loss: 0.1741 - acc: 0.9563 - val_loss: 0.1838 - val_acc: 0.9500\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 1s 566us/sample - loss: 0.1390 - acc: 0.9681 - val_loss: 0.1531 - val_acc: 0.9650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f8225f8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model1.fit(x=text_pad,y=Y,batch_size=100,epochs=10,verbose=1,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method attention.call of <__main__.attention object at 0x1411e8390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method attention.call of <__main__.attention object at 0x1411e8390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 32, 32)            66304     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 32, 100)           53200     \n",
      "_________________________________________________________________\n",
      "attention (attention)        (None, 100)               132       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 119,838\n",
      "Trainable params: 119,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs=Input((32,))\n",
    "x=Embedding(input_dim=len(t.word_index.items())+1,output_dim=32,input_length=32,\\\n",
    "            embeddings_regularizer=keras.regularizers.l2(.001))(inputs)\n",
    "att_in=LSTM(100,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(x)\n",
    "att_out=attention()(att_in)\n",
    "outputs=Dense(2,activation='sigmoid',trainable=True)(att_out)\n",
    "model=Model(inputs,outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1417739d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepanshu.kandpal/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1417739d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepanshu.kandpal/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.7288 - acc: 0.5059 - val_loss: 0.7173 - val_acc: 0.4125\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 1s 591us/sample - loss: 0.7016 - acc: 0.5219 - val_loss: 0.7100 - val_acc: 0.4125\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 1s 607us/sample - loss: 0.6755 - acc: 0.5813 - val_loss: 0.6263 - val_acc: 0.6587\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 1s 595us/sample - loss: 0.4858 - acc: 0.7897 - val_loss: 0.3747 - val_acc: 0.8650\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 1s 604us/sample - loss: 0.3360 - acc: 0.8813 - val_loss: 0.2706 - val_acc: 0.9150\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 1s 626us/sample - loss: 0.2017 - acc: 0.9413 - val_loss: 0.1796 - val_acc: 0.9475\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 1s 603us/sample - loss: 0.1362 - acc: 0.9669 - val_loss: 0.1126 - val_acc: 0.9775\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 1s 600us/sample - loss: 0.0896 - acc: 0.9819 - val_loss: 0.1042 - val_acc: 0.9775\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 1s 613us/sample - loss: 0.0579 - acc: 0.9881 - val_loss: 0.0520 - val_acc: 0.9925\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 1s 601us/sample - loss: 0.0511 - acc: 0.9887 - val_loss: 0.0753 - val_acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1416d4a90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(x=text_pad,y=Y,batch_size=100,epochs=10,verbose=1,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
